# GEMINI_API_KEY=AIzaSyBJuhZhYPsg5O5xt3sSBDJ6NFhd6Sha_Wk
mistral_llm_config = {
    "config_list": [
        {
            "model": "mistral",
            "base_url": "http://localhost:11434/v1",
            "api_key": "ollama",
            "api_type": "openai",
        }
    ]
}